{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4ec5c2ad-4e30-4f57-91b0-78d785055b07",
      "metadata": {
        "id": "4ec5c2ad-4e30-4f57-91b0-78d785055b07"
      },
      "source": [
        "# Week 4: Lab Work - Regression Model Development and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucpCKkmEKGYf",
        "outputId": "9416bd0f-732c-4d20-a556-b73417c2f9e3"
      },
      "id": "ucpCKkmEKGYf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c78a005-f726-40d2-9d4f-e2c1a39127e6",
      "metadata": {
        "id": "2c78a005-f726-40d2-9d4f-e2c1a39127e6"
      },
      "outputs": [],
      "source": [
        "# Import the libraries required, for example: import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6081557f-8acf-4ced-92f0-ebf22b63a83f",
      "metadata": {
        "id": "6081557f-8acf-4ced-92f0-ebf22b63a83f"
      },
      "source": [
        "## Load ‘tips’ data set from seaborn library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41cd5ba1-849f-4146-8066-8ad564a1b031",
      "metadata": {
        "id": "41cd5ba1-849f-4146-8066-8ad564a1b031"
      },
      "outputs": [],
      "source": [
        "# Load the dataset \"tips\" from seaborn package using sns object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6405e9e-8443-4d42-a769-af6156014a7b",
      "metadata": {
        "id": "f6405e9e-8443-4d42-a769-af6156014a7b"
      },
      "outputs": [],
      "source": [
        "# Print the head of the dataset to have an idea.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1038339f-d13f-4284-beda-548e90353c61",
      "metadata": {
        "id": "1038339f-d13f-4284-beda-548e90353c61"
      },
      "outputs": [],
      "source": [
        "# Check the size of the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe55511b-2466-4d39-9d77-4aef1049f379",
      "metadata": {
        "id": "fe55511b-2466-4d39-9d77-4aef1049f379"
      },
      "outputs": [],
      "source": [
        "# Check the variables/columns and the data types and see if we can predict tips using total_bill for example? You can use info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9afa478c-3851-4e3f-8312-40d8523d2f01",
      "metadata": {
        "id": "9afa478c-3851-4e3f-8312-40d8523d2f01"
      },
      "source": [
        "## <font color='red'>Objective</font>: Using Linear Regression Algorithm, we aim to predict tips on the basis of total bill."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d364c32-24b5-4447-9a14-a3132aae149e",
      "metadata": {
        "id": "1d364c32-24b5-4447-9a14-a3132aae149e"
      },
      "outputs": [],
      "source": [
        "# Can you plot a scatterplot below to see whether total bill tends to proprotionally increase with the tip?\n",
        "# This way we can be sure to use 'total_bill' feature to predict 'tip' target value by observing the correlation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26e42383-0f77-4324-b0ad-21b1718a7882",
      "metadata": {
        "id": "26e42383-0f77-4324-b0ad-21b1718a7882"
      },
      "outputs": [],
      "source": [
        "# Consider using regplot() or lmplot function to see this trend much clearly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a792c4-66fb-4f94-87ae-288306fe6a77",
      "metadata": {
        "id": "c0a792c4-66fb-4f94-87ae-288306fe6a77"
      },
      "source": [
        "# Model Development"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5e26b0a-e4c0-48b7-b402-490d6328d18e",
      "metadata": {
        "id": "c5e26b0a-e4c0-48b7-b402-490d6328d18e"
      },
      "source": [
        "## Divide the dataset into two parts, X for total_bill features/predictors, y for tip target value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7dbc047-9665-47f5-a1f8-4073888cae8d",
      "metadata": {
        "id": "c7dbc047-9665-47f5-a1f8-4073888cae8d"
      },
      "outputs": [],
      "source": [
        "# Write HERE\n",
        "\n",
        "# Better to define features as a dataframe [[]]\n",
        "# Predicted value can be defined as series []\n",
        "# The target variable (y) is often defined as a Series because it represents a single column of values corresponding to the output labels or\n",
        "# regression targets. Machine learning models are generally fine with the target variable being in a one-dimensional format.\n",
        "# Since y only holds the target values, there's no need to keep it in a 2D DataFrame format, e.g. (244,1)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "891bc0c6-c542-4c19-9047-f42d1b2943c1",
      "metadata": {
        "id": "891bc0c6-c542-4c19-9047-f42d1b2943c1"
      },
      "source": [
        "# Train-Test Split\n",
        "- Train-test split is a technique used in machine learning to evaluate the performance of a model on unseen data. It is used to split the data into two parts: a training set and a test set. The training set is used to train the model, while the test set is used to evaluate the model’s performance on unseen data. This helps to ensure that the model is not overfitting the data, and that it is generalizing well to unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cfe28bd-633a-4ee4-aea8-e62d582162f7",
      "metadata": {
        "id": "8cfe28bd-633a-4ee4-aea8-e62d582162f7"
      },
      "outputs": [],
      "source": [
        "#Split the data into training and test sets using train_test_split. Spare 80% for training set and 20% for the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee34022-b5e8-4493-8a62-08704d704717",
      "metadata": {
        "id": "6ee34022-b5e8-4493-8a62-08704d704717"
      },
      "outputs": [],
      "source": [
        "# You can check the size of each variables: X_train, X_test, y_train, y_test whether they match in size using data.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ccae51-bddd-491e-b51d-0c1ef52c1ed7",
      "metadata": {
        "id": "d8ccae51-bddd-491e-b51d-0c1ef52c1ed7"
      },
      "outputs": [],
      "source": [
        "# Define Linear Regression model\n",
        "# Write your code HERE\n",
        "\n",
        "## General approach\n",
        "# 1- Identify and allocate X and y, features and the target value.\n",
        "# 2- Split the dataset into X_train, X_test, y_train, y_test.\n",
        "# 3- Determine the model - whether it is linear regression/random forest etc. you want to use?\n",
        "# 4- Fit the data - train X_train with y_train so as to teach the model the correlation between X and y.\n",
        "# 4th step is done so that Beta values are estimated, which can then be used to estimate the y values on a new unseen data (X_test in our case).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3936e3b2-8db8-4b27-a4be-f848d6fe2981",
      "metadata": {
        "id": "3936e3b2-8db8-4b27-a4be-f848d6fe2981"
      },
      "outputs": [],
      "source": [
        "# Fit the model to the given data, X_train is fitted with weights (Beta values from in-class slides) to the value y_train, using fit() function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4475da-045f-485a-8479-654eab0bf372",
      "metadata": {
        "id": "cc4475da-045f-485a-8479-654eab0bf372"
      },
      "outputs": [],
      "source": [
        "# Make prediction using the unseen X_test data using predict() function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb563db9-839e-4477-8f84-015f8babb1e0",
      "metadata": {
        "id": "fb563db9-839e-4477-8f84-015f8babb1e0"
      },
      "outputs": [],
      "source": [
        "# Plot the true data points of X_test and y_test using regplot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdc83f40-4ae7-4d54-a8b1-8cde05c6624b",
      "metadata": {
        "id": "fdc83f40-4ae7-4d54-a8b1-8cde05c6624b"
      },
      "outputs": [],
      "source": [
        "# Plot the predicted target value 'tip', you can use regplot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "454bcd7f-b211-44f7-b52b-7b5c708df4e8",
      "metadata": {
        "id": "454bcd7f-b211-44f7-b52b-7b5c708df4e8"
      },
      "outputs": [],
      "source": [
        "# Use MAE to measure the average magnitude of the errors in a set of predictions.\n",
        "# Closer to zero means better accuracy.\n",
        "from sklearn.metrics import mean_absolute_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c484341a-4257-41e3-840d-ca61a881ecca",
      "metadata": {
        "id": "c484341a-4257-41e3-840d-ca61a881ecca"
      },
      "outputs": [],
      "source": [
        "# Use RMSE to measure the average of the suares of the errors or deviations from the actual value.\n",
        "# It is used to measure the accuracy of a model in predicting the outcome of a given data set.\n",
        "# Closer to zero means better accuracy.\n",
        "from sklearn.metrics import mean_squared_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "807a9cb0-1403-481d-87c9-8f89e54c9431",
      "metadata": {
        "id": "807a9cb0-1403-481d-87c9-8f89e54c9431"
      },
      "outputs": [],
      "source": [
        "# Extra information on evaluation of regression, search for 'R^2 score' and implement.\n",
        "# Closer to one means better accuracy.\n",
        "from sklearn.metrics import r2_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print y_prediction vs y_test side-by-side to visibly compare.\n"
      ],
      "metadata": {
        "id": "I33qclcMLxvY"
      },
      "id": "I33qclcMLxvY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new function that calculates the mean absolute error from y_test to y_predictions using the function name: mean_abs_err()\n"
      ],
      "metadata": {
        "id": "IH1Po2KZL3jY"
      },
      "id": "IH1Po2KZL3jY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the above function, as follows, with the y_test and y_predictions, and compare to the embedded mean_squared_error function outcome we used above. We expect them to be the same!\n",
        "mean_abs_err(y_test, y_predictions)"
      ],
      "metadata": {
        "id": "RurOASSPMLGE"
      },
      "id": "RurOASSPMLGE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenging task (optional)\n",
        "*   **Predict housing prices**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1wO62YKYLzYl"
      },
      "id": "1wO62YKYLzYl"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BwYlfP8L50r",
        "outputId": "2325db29-6319-4ff4-b15d-e5038517d2cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "id": "4BwYlfP8L50r"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "# Some necessary ones are given below ....\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Load dataset: housing.csv\n",
        "\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "# Drop non-numeric columns\n",
        "\n",
        "\n",
        "# Handle missing values by filling with median if any\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mIiv9q0IQjOB"
      },
      "execution_count": null,
      "outputs": [],
      "id": "mIiv9q0IQjOB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Exploratory Data Analysis (EDA)\n",
        "# Compute and visualize the correlation matrix\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JRA1JLfCkfAk"
      },
      "execution_count": null,
      "outputs": [],
      "id": "JRA1JLfCkfAk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Feature Selection Using Variance Inflation Factor (VIF) (Multicollinearity Handling)\n",
        "# Search for VIF and understand the context before using it\n",
        "# Write a function to calculate VIF for each feature using variance_inflation_factor function\n",
        "\n",
        "\n",
        "# Call the aforementioned function to Compute VIF and see highly collinear features in the dataset\n",
        "\n",
        "\n",
        "# Remove features with high multicollinearity, i.e., VIF > 30\n"
      ],
      "metadata": {
        "id": "67q0p4uXkhAl"
      },
      "execution_count": null,
      "outputs": [],
      "id": "67q0p4uXkhAl"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Splitting Data for Model Training, 'Price' is your target variable\n",
        "\n"
      ],
      "metadata": {
        "id": "5HjDS-m_NQBC"
      },
      "execution_count": null,
      "outputs": [],
      "id": "5HjDS-m_NQBC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Training and Evaluating a Linear Regression Model\n",
        "# Select and Train Linear Regression Model\n",
        "\n",
        "\n",
        "# Predict using the model and X_test\n",
        "\n",
        "## Model Evaluation using RMSE and R^2 and print the outputs using the following prints\n",
        "# write HERE for the evaluation of RME and R^2\n",
        "\n",
        "# print the output\n",
        "print(\"\\nLinear Regression Model Evaluation:\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.3f}\")\n",
        "print(f\"R² Score: {r2:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "AFmXHYSzkpvF"
      },
      "execution_count": null,
      "outputs": [],
      "id": "AFmXHYSzkpvF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Search for Regularisation with Ridge and Lasso Regression and use them in this task to improve results and observe if it helps\n",
        "# Play with alpha values and observe if there is any changes\n",
        "# RIDGE\n",
        "\n",
        "# LASSO\n",
        "\n",
        "# print the output\n",
        "print(\"\\nRegularization Results:\")\n",
        "print(f\"Ridge Regression - RMSE: {ridge_rmse:.3f}, R²: {ridge_r2:.3f}\")\n",
        "print(f\"Lasso Regression - RMSE: {lasso_rmse:.3f}, R²: {lasso_r2:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "0Dpco7HckskY"
      },
      "execution_count": null,
      "outputs": [],
      "id": "0Dpco7HckskY"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Feature Importance\n",
        "# Get feature importance using the Linear Regression coefficients and print\n",
        "\n"
      ],
      "metadata": {
        "id": "iEa_BRUkkvHj"
      },
      "execution_count": null,
      "outputs": [],
      "id": "iEa_BRUkkvHj"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Change VIF value from 30 to 50 at the end of Step 3 and observe/comment on your findings.\n",
        "# How did this change affect the selected features and the model performance?"
      ],
      "metadata": {
        "id": "nWlzxvGwkxVX"
      },
      "execution_count": null,
      "outputs": [],
      "id": "nWlzxvGwkxVX"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tuVyL380jwfA"
      },
      "id": "tuVyL380jwfA"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2JWMsISBkIg1"
      },
      "id": "2JWMsISBkIg1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}