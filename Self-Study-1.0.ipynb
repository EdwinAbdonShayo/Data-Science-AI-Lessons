{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning for Road Accident Severity Prediction\n",
    "From the labeled dataset (with \"*Accident Severity*\" as the target variable), the **Supervised Learning Models** will be used for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Learning Models\n",
    "We will use different supervised classification models to predict *Accident Severity (Minor, Moderate, Severe)*.\n",
    "\n",
    "### Data Preprocessing\n",
    "1. Convert categorical variables (e.g., Weather Conditions, Road Type, Driver Age Group) into numerical values using one-hot encoding.\n",
    "2. Normalize numerical values (e.g., Speed Limit, Visibility Level, Traffic Volume) to ensure consistent model performance.\n",
    "3. Handle missing values (if any) by imputation or removal.\n",
    "\n",
    "### Splitting the Data\n",
    "- 80% for training, 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=[\"Accident Severity\"])  # Features\n",
    "y = df[\"Accident Severity\"]  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Supervised Learning Models\n",
    "\n",
    "We will train and compare multiple classification models\n",
    "\n",
    "1. **Decision Trees**\n",
    "    - Simple and interpretable.\n",
    "    - Can handle categorical and numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Random Forest (Ensemble Model)**\n",
    "    - Simple and interpretable.\n",
    "    - Can handle categorical and numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **XGBoost (Boosting Model)**\n",
    "    - More powerful for structured data.\n",
    "    - Uses gradient boosting to minimize error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Appropriate Evaluation Metrics\n",
    "For classification models, we will evaluate using:\n",
    "\n",
    "* **Accuracy** â€“ Measures the overall correctness of predictions.\n",
    "* **Precision** â€“ Measures how many predicted severe accidents were actually severe.\n",
    "* **Recall** â€“ Measures how many actual severe accidents were correctly identified.\n",
    "* **F1-score** â€“ Balances precision and recall for better overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(y_test, y_pred, model_name):\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.2f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.2f}\")\n",
    "    print(f\"F1-score: {f1_score(y_test, y_pred, average='weighted'):.2f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "evaluate_model(y_test, y_pred_xgb, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide a Clear Interpretation of Model Performance\n",
    "To visualize performance, we can generate:\n",
    "\n",
    "1. **Classification Report & Confusion Matrix**\n",
    "    - A confusion matrix shows where the model makes mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Classification Report for Random Forest\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix for Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Feature Importance (Understanding What Factors Influence Severity)**\n",
    "    * Helps identify which features impact accident severity the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_importances = pd.DataFrame({'Feature': X_train.columns, 'Importance': rf_model.feature_importances_})\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot Feature Importance\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances)\n",
    "plt.title(\"Feature Importance in Accident Severity Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **ROC Curve (Performance Across Different Thresholds)**\n",
    "    * Helps evaluate how well the model distinguishes between severity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "y_probs = rf_model.predict_proba(X_test)  # Get probability scores\n",
    "y_test_bin = np.where(y_test == \"Severe\", 1, 0)  # Convert labels to binary\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_bin, y_probs[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"grey\", linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for Accident Severity Prediction\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "- **Train Models**: Decision Trees, Random Forest, XGBoost\n",
    "\n",
    "- **Evaluate**: Accuracy, Precision, Recall, F1-score\n",
    "\n",
    "- **Visualize & Interpret**: Confusion Matrix, Feature Importance, ROC Curve\n",
    "\n",
    "*This approach will help **identify risk factors for severe accidents** and **improve road safety interventions**. ðŸš¦*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
